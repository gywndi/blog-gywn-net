<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MariaDB on gywn&#39;s tech</title>
    <link>//localhost:1313/categories/mariadb/</link>
    <description>Recent content in MariaDB on gywn&#39;s tech</description>
    <generator>Hugo</generator>
    <language>en</language>
    <managingEditor>gywndi@gmail.com (gywndi)</managingEditor>
    <webMaster>gywndi@gmail.com (gywndi)</webMaster>
    <lastBuildDate>Tue, 19 Aug 2025 20:01:39 +0900</lastBuildDate>
    <atom:link href="//localhost:1313/categories/mariadb/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fluentd? 나만의 에이전트 패키징!</title>
      <link>//localhost:1313/2021/09/package-own-fluentd-agent/</link>
      <pubDate>Tue, 07 Sep 2021 03:26:39 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2021/09/package-own-fluentd-agent/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;세상에는 수많은 모니터링 도구들이 있습니다. 최근 많이 사용하고 있는 시계열 데이터베이스인 Prometheus와 수많은 exporter가 그중 하나입죠. 매트릭 수집에 최적화된 이런 구성은 시스템의 상태 값을 수집하기에는 더없이 좋은 시스템이기는 합니다만, 로그성 데이터 수집(에러로그 혹은 syslog)에는 아무래도 한계를 가집니다.&lt;/p&gt;&#xA;&lt;p&gt;이 경우, td-agent와 같은 범용적인 로그 수집 에이전트를 활용하게 되는데요. (혹은 자체적으로 구현을 하거나) 타팀과 혼재해서 사용하는 경우 문제 발생소지가 있긴합니다. 참고로, td-agent는 ruby 뿐만 아니라, 필요한 라이브러리들을 패키지 내부에 포함시켜서, OS 의존성을 최소화합니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Go언어로 나만의 Query Exporter 만들어보기!</title>
      <link>//localhost:1313/2021/07/make-own-query-exporter-with-go/</link>
      <pubDate>Tue, 13 Jul 2021 05:39:54 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2021/07/make-own-query-exporter-with-go/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;안녕하세요. 무더운 7월 잘 지내고 계시죠.?&lt;/p&gt;&#xA;&lt;p&gt;오늘은 조금 특이한 주제를 가지고 이야기를 해보고자 합니다. 바로 &lt;strong&gt;go로 나만의 Exporter를 만들어보는 것&lt;/strong&gt;입니다. 특정 쿼리를 등록을 해놓으면, 이 쿼리 결과를 Exporter 결과로 보여주는 간단한 프로그램입니다. 아직 Expoter가 무엇인지 생소하신 분들이 있을 수 있겠는데요. 오늘 차근차근 설명을 하면서, 머릿속에 살짝 인스톨해드리도록 하겠습니다. 🙂&lt;/p&gt;&#xA;&lt;h1 id=&#34;exporter&#34;&gt;Exporter?&lt;/h1&gt;&#xA;&lt;p&gt;Exporter란, Prometheus같은 시계열 데이터베이스에서 데이터를 끌어가기 위한 하나의 &lt;strong&gt;HTTP 서버&lt;/strong&gt;라고 생각하면 되겠습니다. Prometheus에서는 정해진 주기에 따라 exporter의 특정 URL을 호출하고, 그 결과값을 시계열로 데이터를 저장합니다.&#xA;&lt;img src=&#34;//localhost:1313/img/2021/07/prometheus-exporter.png&#34; alt=&#34;prometheus &amp;amp; exporter&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL에서 리셋되는 시퀀스 만들어보기</title>
      <link>//localhost:1313/2021/06/resetable-sequence-for-mysql/</link>
      <pubDate>Mon, 21 Jun 2021 06:24:06 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2021/06/resetable-sequence-for-mysql/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;서비스를 준비하다보면, 시퀀스에 대한 요구사항은 언제나 생기기 마련입니다. 물론, MySQL에는 기본적으로 테이블 단위로 auto_increment가 있기는 합니다만, 일반적인 시퀀스가 요구되는 환경을 흡족하게 맞추기는 어려운 실정입니다.&lt;br&gt;&#xA;보통은 Peter Zaitsev가 하단에 게시한 블로그 내용처럼, Function 기반으로 채번 함수를 만들고는 하지요. (물론 InnoDB로 지정하는 것이, 복제 상황에서는 아주 안정성을 확보하기는 합니다.)&lt;br&gt;&#xA;&lt;a href=&#34;https://www.percona.com/blog/2008/04/02/stored-function-to-generate-sequences/&#34;&gt;https://www.percona.com/blog/2008/04/02/stored-function-to-generate-sequences/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;이 내용을 기반으로, “재미난 시퀀스를 만들어볼 수 없을까?” 라는 퀘스천에 따라, 이번 블로깅에서는 특정 시점에 리셋이 되는 시퀀스를 한번 만들어보고자 합니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;schema&#34;&gt;Schema&lt;/h1&gt;&#xA;&lt;p&gt;첫번째로는 현재 시퀀스를 담을 테이블 그릇(?)을 아래와 같이 생성을 해보도록 하겠습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL binlog파서와 memcached plugin의 콜라보레이션!</title>
      <link>//localhost:1313/2020/08/mysql-binlog-memcached-plugin-collaboration/</link>
      <pubDate>Mon, 31 Aug 2020 00:55:06 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2020/08/mysql-binlog-memcached-plugin-collaboration/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;6개월도 훌쩍 넘은 시간에. 간만에 포스팅합니다. 그동안 OGG javaue든, MySQL Binlog파서든.. &lt;strong&gt;흐르는 데이터를 핸들링하는 고민&lt;/strong&gt;으로 하루하루를 지내왔던 것 같아요. 그러던 중 이전 포스팅에서 주제로 삼았던, &lt;strong&gt;InnoDB memcached plugin을 Binlog parsing을 통해 데이터를 맞추면 좋을 것 같다&lt;/strong&gt;는 생각이 들었습니다.&lt;br&gt;&#xA;오늘 이 자리에서는 이런 답답함을 극복하고자, Binlog 이벤트를 활용하여, 최신 데이터를 유지시키는 방안에 대해서 이야기를 해보도록 하겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;mysql-binary-log&#34;&gt;MySQL Binary log?&lt;/h1&gt;&#xA;&lt;p&gt;MySQL에서 데이터복제를 위해서는 Binnary Log(binlog)를 쓰게 되는데, 이중 ROW 포멧으로 만들어지는 이벤트를 활용하여 다양한 데이터 핸들링이 가능합니다.&lt;br&gt;&#xA;&lt;img src=&#34;//localhost:1313/2020/08/image-1598580840319.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL InnoDB의 메모리 캐시 서버로 변신! – 활용편 –</title>
      <link>//localhost:1313/2020/01/mysql-innodb-as-cache-server-monitoring-advanced/</link>
      <pubDate>Mon, 06 Jan 2020 14:10:44 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2020/01/mysql-innodb-as-cache-server-monitoring-advanced/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;벌써 새해가 밝았네요. 새해 복 많이 받고 계시쥬?&lt;/p&gt;&#xA;&lt;p&gt;판교 생활을 한지도 벌써 만 7년을 훌쩍 지나, 8년을 향해 가고 있군요. 2020년 우주의 원더키디(아재 인증)의 그 시간이 이렇게나 빠르게 찾아올 줄은 그때의 저는 몰랐답니다. ㅠㅠ&lt;/p&gt;&#xA;&lt;p&gt;오늘 주제는, 그동안 MySQL innodb memcached 플러그인의 마지막편, (지극히 개인적인 의견인) 서비스적인 활용 편입니다. 상상의 날개를 펼쳐서, 서비스 최우선적인 활용을 위해 무엇을 꿈꿔볼 수 있을지, 이야기 해보고자 합니다. (이전 포스팅은 하단을 참고요.)&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;//localhost:1313/2019/09/mysql-innodb-as-cache-server-config/&#34;&gt;1탄. MySQL InnoDB의 메모리 캐시 서버로 변신! – 설정편 –&lt;/a&gt;&lt;br&gt;&#xA;&lt;a href=&#34;//localhost:1313/2019/09/mysql-innodb-as-cache-server-monitoring/&#34;&gt;2탄. MySQL InnoDB의 메모리 캐시 서버로 변신! – 모니터링편 –&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL InnoDB의 메모리 캐시 서버로 변신! – 모니터링편 –</title>
      <link>//localhost:1313/2019/09/mysql-innodb-as-cache-server-monitoring/</link>
      <pubDate>Thu, 19 Sep 2019 14:28:50 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2019/09/mysql-innodb-as-cache-server-monitoring/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL memcached plugin 2탄! 모니터링편입니다.&lt;br&gt;&#xA;어떤 초호화 솔루션일지라도, 시스템의 정확한 상태를 파악할 수 없다면, 사용하기에는 참으로 꺼려집니다. 그래서 어떤 방법이든, &lt;strong&gt;가장 효율적인 모니터링 방안&lt;/strong&gt;을 찾아봐야 하겠는데요. 저는 개인적으로는 &lt;strong&gt;prometheus를 활용한 metric수집을 선호&lt;/strong&gt;합니다.&lt;br&gt;&#xA;오늘 이 자리에서는 Prometheus에서 MySQL InnoDB memcached plugin을 모니터링 하는 방법에 대해서 이야기를 해보도록 하겠습니다. 🙂&lt;/p&gt;&#xA;&lt;h1 id=&#34;why-prometheus&#34;&gt;Why prometheus?&lt;/h1&gt;&#xA;&lt;p&gt;이유는 단순합니다. &lt;strong&gt;이미 만들어져 있는 exporter가 굉장히 많다&lt;/strong&gt;는 것, 만약 원하는 것들이 있다면 &lt;strong&gt;나의 구미에 맞게 기능을 추가해서 쉽게 접근할 수 있다&lt;/strong&gt;는 것! 즉, &lt;strong&gt;오픈소스&lt;/strong&gt;라는 것!! 무엇보다 Time-series 기반의 데이터 저장소인 Prometheus로 정말로 효율적으로 모니터링 매트릭 정보를 수집할 수 있다는 것! Prometheus는 &lt;strong&gt;로그 수집에 최적화&lt;/strong&gt; 되어 있다고 과언이 아닙니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL InnoDB의 메모리 캐시 서버로 변신! – 설정편 –</title>
      <link>//localhost:1313/2019/09/mysql-innodb-as-cache-server-config/</link>
      <pubDate>Sun, 15 Sep 2019 11:50:15 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2019/09/mysql-innodb-as-cache-server-config/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;꽤나 오래전의 일이었습니다. MariaDB에서 Handler Socket이 들어간 이후 얼마 후인 것으로 기억합니다. &lt;strong&gt;MySQL lab버전에 memcached plugin 기능이 추가&lt;/strong&gt;되었고, &lt;strong&gt;memcache protocal로 InnoDB 데이터에 직접 접근&lt;/strong&gt;할 수 있는 길이 열린 것이었죠. (아마도 거의 8년 정도 전의 일이었던 것같은..) 아무튼 당시, 이것에 대해 간단하게 테스트만 해보고, MySQL을 캐시형태로 잘 활용할 수 있겠다라는 희망만 품고 지나버렸다는 기억이 나네요.&lt;/p&gt;&#xA;&lt;p&gt;이제 Disk는 과거의 통돌이 디스크가 아니죠. 기계 장치를 탈피하여, 이제는 모터없는 전자기기.. &lt;strong&gt;SSD의 시대가 도래&lt;/strong&gt;하였습니다. 통돌이 대비, 어마어마한 수치의 Random I/O를 제공해주는만큼, 이제 DB 데이터에 새로운 패러다임(?)으로 접근할 수 있겠다는 시점이 온 것 같아요.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL 파티셔닝 테이블 SELECT가 느려요.</title>
      <link>//localhost:1313/2019/08/mysql-poor-performance-with-super-many-partitions/</link>
      <pubDate>Thu, 29 Aug 2019 14:56:26 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2019/08/mysql-poor-performance-with-super-many-partitions/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;네이티브 파티셔닝 적용 이전의 MySQL은, 파티셔닝 파일들은 각각이 테이블로써 관리되었죠. 그래서, table cache 로 인한 메모리 부족 현상은 인지하고 있었습니다만.. 이것 외에는 특별히 성능 저하 요소는 없다고 생각해왔어요. (&lt;a href=&#34;http://small-dbtalk.blogspot.com/2013/09/mysql-table-cache.html&#34;&gt;http://small-dbtalk.blogspot.com/2013/09/mysql-table-cache.html&lt;/a&gt;)&lt;/p&gt;&#xA;&lt;p&gt;그런데, 얼마전 서버당 4개의 데이터베이스를 만들고, 각각 데이터베이스 안에 26개월로 분할된 파티셔닝된 테이블을 넣고, 간단한 Range scan 성능 테스트를 하였는데.. 말도안되는 수치를 보였습니다. 이 관련하여 간단하게 이에 대해 알아보도록 할께요. 🙂&lt;/p&gt;&#xA;&lt;h1 id=&#34;problem&#34;&gt;Problem&lt;/h1&gt;&#xA;&lt;p&gt;하단과 같은 테이블 구조에서, 단순히 최근 10건의 데이터만 끌어오는 형식의 SQL을 다수 실행시켜 간단한 트래픽을 주었을 때.. 성능적으로 별다른 문제는 없을 것이라고 생각을 했습니다. 우리의 메모리는 기대치보다 훨씬 웃돌았기 때문에.. ㅎㅎ (참고로, InnoDB 버퍼풀 사이즈 대비 데이터 사이즈는 약 10배 이상이지만, 최근 파티셔닝 사이즈를 따지면, 버퍼풀 안에 충분히 들어올만한 상황이었습니다.)&lt;/p&gt;</description>
    </item>
    <item>
      <title>PMM팁1탄! MySQL을 READ-ONLY 기준으로 표기해보기.</title>
      <link>//localhost:1313/2019/01/pmm-tip1-classified-by-mysql-readonly/</link>
      <pubDate>Mon, 28 Jan 2019 23:58:03 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2019/01/pmm-tip1-classified-by-mysql-readonly/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;어느덧 1월이 마무리되어가는 이 시점.. 한달 내내 놀다 시간 보내기에는 아쉬움이 많이 남아, 블로그 한두개 정도는 남겨보고자, 아주 간만에 노트북 앞에 앉습니다. 가장 기억 속에 맴도는 주제를 찾던 중, 작년 나름 많은 분석을 했었던 내용들을 한번 몇가지 주제로 정리해보고자 합니다.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;PMM&lt;/strong&gt;(&lt;strong&gt;P&lt;/strong&gt;ercona &lt;strong&gt;M&lt;/strong&gt;onitoring and &lt;strong&gt;M&lt;/strong&gt;anagement)이라는 녀석으로 퉁 쳐서 이야기를 했지만, 사실 이번에 이야기할 내용은 Prometheus 쿼리와 Grafana를 사용하는 간단한 꼼수(?)에 대한 이야기입니다.&lt;/p&gt;&#xA;&lt;p&gt;혹시 PMM이 어떤 녀석인지 궁금하시다면? &lt;a href=&#34;//localhost:1313/2018/03/pmm-intro/&#34;&gt;PMM 이야기 1편 – INTRO&lt;/a&gt; 편을 읽어보주세요. ㅎㅎ&lt;/p&gt;</description>
    </item>
    <item>
      <title>[MySQL] Online Alter에도 헛점은 있더구나 – gdb, mysqld-debug 활용 사례</title>
      <link>//localhost:1313/2018/10/online-alter-for-varchar/</link>
      <pubDate>Fri, 12 Oct 2018 00:00:52 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2018/10/online-alter-for-varchar/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL에서도 5.6부터는 온라인 Alter 기능이 상당부분 제공되기 시작했습니다. 인덱스과 칼럼 추가/삭제 뿐만 아니라, varchar 경우에는 부분적으로 칼럼 확장이 서비스 중단없이 가능한 것이죠. 물론 오라클 유저들에게는 당연한 오퍼레이션들이, MySQL에서는 두손들고 운동장 20바퀴 돌 정도로 기뻐할만한 기능들입니다. 물론, 대부분의 DDL을 테이블 잠금을 걸고 수행하던 5.5 시절에도 online alter를 위해 트리거 기반의 pt-online-schema-change 툴을 많이들 사용했었기에.. 서비스 중단이 반드시 필요하지는 않았지만요. (&lt;a href=&#34;//localhost:1313/2017/08/small-talk-pt-osc/&#34;&gt;소소한 데이터 이야기 – pt-online-schema-change&lt;/a&gt;)&lt;/p&gt;&#xA;&lt;p&gt;아무튼 이렇게 online alter가 대거 지원하는 상황 속에서, MySQL의 메뉴얼과는 다르게 잘못 동작하는 부분이 있었는데, 이 원인을 찾아내기 위해서는 MySQL 내부적으로 어떻게 동작을 하는지 알아내기 위해 며칠 우물을 신나게 파보았습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL에서 Affected Rows를 병맛나게 활용해보자.</title>
      <link>//localhost:1313/2018/03/mad-usage-with-mysql-affected-rows/</link>
      <pubDate>Mon, 26 Mar 2018 23:45:20 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2018/03/mad-usage-with-mysql-affected-rows/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;이제 슬슬 날이 풀려가고 있습니다. 얼어붙은 땅이 녹듯이, 오랜시간 얼어있던 블로그 공간도 잠시마나 녹여볼까 합니다. 사실 지난 &lt;a href=&#34;//localhost:1313/2018/03/pmm-intro/&#34;&gt;PMM 이야기 1편&lt;/a&gt; 이후 2편, 3편 쭉 써야하지만.. 이노무 귀차니즘과 여기저기 산재한 낙서들을 아직 정리하지 못한 탓에.. 쿨럭..&lt;/p&gt;&#xA;&lt;p&gt;사실 오늘 얘기할 내용은 3년도 훨씬 전 내용으로, 블로그로 이미 정리했다고 지금까지 착각을 했던 이야기입니다. 바로 &lt;code&gt;Affected Rows&lt;/code&gt; 값을 활용해서, 다양한 요구 사항을 조금 더 재미있게 풀어보자는 내용이죠.&lt;/p&gt;&#xA;&lt;h1 id=&#34;affected-rows&#34;&gt;Affected Rows?&lt;/h1&gt;&#xA;&lt;p&gt;다들 아시겠지만, Affected Rows는 DML시 실제로 영향을 미친 데이터 Row 수입니다. 보통 update/delete를 날린 후에 몇 건의 데이터가 변경이 되었는지를 CLI툴에서 확인하는 용도로만 제 경우에는 많이 사용하고는 했습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>JDBC의 autoReconnect 파라메터가 저지른 일!</title>
      <link>//localhost:1313/2017/10/jdbc-insane-autoreconnect/</link>
      <pubDate>Tue, 31 Oct 2017 00:00:00 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2017/10/jdbc-insane-autoreconnect/</guid>
      <description>&lt;p&gt;세상에 말도 안되는 일이 일어났습니다.&lt;/p&gt;&#xA;&lt;p&gt;서비스가 정상적으로 동작하기 위해서는, 아무래도 데이터베이스가 필수인데.. 이 데이터베이스로부터 쉽게 데이터를 주고받을 수 있게 디비별/언어별 중간 역할을 해주는 것이 바로 Driver입니다.&lt;/p&gt;&#xA;&lt;p&gt;MySQL역시 자바에서 원활하게 데이터 처리를 수행할 수 있도록 &lt;code&gt;connector/j&lt;/code&gt;라는 녀석을 Oracle에서 배포를 하는데.. 오늘은 이 녀석이 제공해주는 기능인 &lt;code&gt;autoReconnect&lt;/code&gt; 파라메터가 저지르는 일에 대해서 얘기를 해보고자 합니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;autoreconnect는-무슨-일을-하는가&#34;&gt;autoReconnect는 무슨 일을 하는가?&lt;/h1&gt;&#xA;&lt;p&gt;파라메터 이름 그대로.. 자동으로 커넥션을 다시 맺어준다는 의미입니다. 데이터베이스 역시 서버로 구동하는 프로그램의 한 축이기에.. 클라이언트가 맺은 커넥션이 절대 끊어지지 않는다고 보장할 수 없습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>소소한 데이터 이야기 – pt-online-schema-change 편 –</title>
      <link>//localhost:1313/2017/08/small-talk-pt-osc/</link>
      <pubDate>Wed, 23 Aug 2017 22:20:31 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2017/08/small-talk-pt-osc/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL 5.6부터는 Online ddl 기능을 제공하기 시작하였지만, 사실은 이전에도 트리거 기반의 online alter 유틸로 서비스 중단없이 테이블 스키마 변경을 수행했었습니다. 이중 percona에서 제공해주는 pt-online-schema-change가 많이들 활용되고 있는데요. 오늘은 돌다리도 망치로 때려가면서 안정성에 신중히 접근한 우리의 케이스에 대해서 데이터 기준으로 얘기를 해보고자 합니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;pt-online-schema-change&#34;&gt;pt-online-schema-change?&lt;/h1&gt;&#xA;&lt;p&gt;얘기하기에 앞서서, 이 툴에 대해서 다시한번 짚어보겠습니다. 대충 동작 순서는 아래와 같이..&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;변경할 스키마 구조의 &lt;strong&gt;임시 테이블을 생성&lt;/strong&gt;하고,&lt;/li&gt;&#xA;&lt;li&gt;insert/update/delete &lt;strong&gt;트리거를 만들어서 최근 변경 데이터를 동기화&lt;/strong&gt;하고,&lt;/li&gt;&#xA;&lt;li&gt;처음부터 끝까지 일정 청크 사이즈로 읽으면서 &lt;strong&gt;임시 테이블에 복사&lt;/strong&gt;한 후,&lt;/li&gt;&#xA;&lt;li&gt;완료되면 &lt;strong&gt;RENAME TABLE&lt;/strong&gt;하여 완료&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;동작합니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>pt-online-schema-change에 숨겨진 무시무시한 이슈!</title>
      <link>//localhost:1313/2016/09/pt-online-schema-change-pk-change-problem/</link>
      <pubDate>Sun, 25 Sep 2016 15:30:47 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2016/09/pt-online-schema-change-pk-change-problem/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;최근들어 거의 연단위로 블로깅을 하나씩 올리는 듯 하는군요. 여기저기 시국이 어지럽고, 바쁘다는 말도 안되는 핑계를 무마시키기 위해.. 아무튼 간만에 블로깅 하나 올려봅니다.&lt;/p&gt;&#xA;&lt;p&gt;MySQL은.. 특히나 온라인 스키마 변경이 취약합니다. 물론 5.6부터는 online alter기능이 포함되어 있다고는 하나.. 100% 완벽하게 모든 상황을 온라인스럽게 제공해주지도 않고.. 그렇다하더라도, 일정 트래픽 이상의 데이터 변경이 이루어지는 경우, 게다가 슬레이브 지연을 염두한다면.. 꺼려지는 상황이 있지요. (참고로, 마스터에서 온라인 스키마 변경이 이루어졌을지라도, 이 관련 alter구문이 슬레이브로 넘어갔을 때는, alter이후 데이터 변경을 수행해야 하므로, 그만큼 복제 지연이 발생합니다. 미네럴~)&lt;/p&gt;</description>
    </item>
    <item>
      <title>파티션 제약 극복기! 유니크한 토큰 값을 만들어보자!</title>
      <link>//localhost:1313/2015/07/generate-unique-token-on-partitioning-table/</link>
      <pubDate>Fri, 03 Jul 2015 14:15:42 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2015/07/generate-unique-token-on-partitioning-table/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL에는 날짜 별 데이터 관리를 위해 파티셔닝이라는 좋은 기능(?)을 5.1버전부터 무료(!)로 제공합니다. 일정 시간 지난 후 불필요한 데이터는 간단하게 해당 파티셔닝을 제거하면, 굳이 DELETE 쿼리로 인한 오버헤드를 방지할 수 있죠.&lt;/p&gt;&#xA;&lt;p&gt;그러나, 파티셔닝 적용 시, **&amp;ldquo;파티셔닝 키는 반드시 PK에 포함되어야 한다&amp;rdquo;, &amp;ldquo;추가 제약조건(유니크 속성)을 부여할 수 없다&amp;rdquo;**라는 대표적인 제약 조건으로 인하여, 유니크 속성을 가지는 데이터를 파티셔닝 적용이 불가한 경우가 있는데.. 이것을 해결할 수 있는 간단한 트릭을 이 자리에서 설명하고자 합니다. ^^&lt;/p&gt;</description>
    </item>
    <item>
      <title>새벽 4시, 이유없이 디스크 유틸이 튄다면? 디스크 성능에 영향을 주는 크론잡</title>
      <link>//localhost:1313/2015/02/linux-cronjob-makes-disk-issue/</link>
      <pubDate>Thu, 05 Feb 2015 12:44:51 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2015/02/linux-cronjob-makes-disk-issue/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;새벽에 디스크 성능에 영향을 주는 요소로는 대표적으로 백업과 같은 디비 운영적인 업무가 있습니다. 각 운영 정책에 따라 다르겠지만, 순간적인 시스템 부하에도 굉장히 민감한 서비스 경우에는 별도의 스탠바이 용도의 슬레이브 서버를 두고 그곳에서 백업을 하기 마련입니다.&lt;/p&gt;&#xA;&lt;p&gt;이런 상황  마스터에서는 백업과 같은 무거운 디스크 작업이 일어나지 않는 상황에서 알 수 없는 이유로 새벽 4시 혹은 4시 22분에 디스크가 유틸이 튀는 경우가 있습니다. 그리고 가벼운 쿼리일지라도 대거 슬로우 쿼리로 잡히기도 합니다.&lt;/p&gt;&#xA;&lt;p&gt;범인은 의외로 리눅스 설치 시 기본적으로 등록되는 두 가지 크론잡에 있는데요, 얼마 전 이와 비슷한 사례를 경험하게 되어 공유 드립니다. (단, 고수님들은 출입금지!)&lt;/p&gt;</description>
    </item>
    <item>
      <title>InnoDB의 Adaptive Hash Index로 쿼리 성능에 날개를 달아보자!!</title>
      <link>//localhost:1313/2015/01/innodb-adaptive-hash-index/</link>
      <pubDate>Thu, 08 Jan 2015 13:28:02 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2015/01/innodb-adaptive-hash-index/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL과 같은 RDBMS에서 대표적으로 가장 많이 사용되는 자료 구조는 B-Tree입니다. 데이터 사이즈가 아무리 커져도 특정 데이터 접근에 소요되는 비용이 크게 증가되지 않기 때문에 어느정도 예상할 수 있는 퍼포먼스를 제공할 수 있기 때문이죠. 그치만 상황에 따라서, B-Tree 사용에 따른 잠금 현상으로 최대의 퍼포먼스를 발휘하지 못하는 경우도 있습니다.&lt;/p&gt;&#xA;&lt;p&gt;이에 대한 해결책으로 InnoDB에는 Adaptive Hash Index 기능이 있는데, 어떤 상황에서 효과가 있고 사용 시 반드시 주의를 해야할 부분에 대해서 정리해보겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;innodb-b-tree-index&#34;&gt;InnoDB B-Tree Index?&lt;/h1&gt;&#xA;&lt;p&gt;소개하기에 앞서서 먼저 InnoDB에서 B-Tree가 어떠한 방식으로 활용되는 지 알아볼까요?&lt;/p&gt;</description>
    </item>
    <item>
      <title>MariaDB의 FederatedX 엔진으로 데이터를 주물러보자.</title>
      <link>//localhost:1313/2014/12/mariadb-federatedx-usage/</link>
      <pubDate>Tue, 30 Dec 2014 13:12:02 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2014/12/mariadb-federatedx-usage/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;FederatedX는 MariaDB에서 제공하는 확장된 기능의 Federated이며, 기본적으로 MariaDB에서는 별다른 옵션 없이 사용할 수 있습니다.&lt;/p&gt;&#xA;&lt;p&gt;바로 이전 포스팅(&lt;a href=&#34;//localhost:1313/2014/12/how-to-migrate-100million-with-federatedx/&#34;&gt;MariaDB의 FederatedX 엔진을 활용한 9억 데이터 이관기&lt;/a&gt;)에서는 이 FederatedX 엔진을 활용하여 대용량 테이블을 서비스에 큰 지장없이 이관을 했던 사례에 대해서 정리를 했었는데요. 이 경험을 바탕으로 서비스에서 조금 더 유용하게 활용할 수 있을 방안에 대해서 상상(?)을 해보았습니다.&lt;/p&gt;&#xA;&lt;p&gt;즉, 지금부터는 FederatedX 엔진 관련된 테스트를 바탕으로 정리하는 내용이오니, 만약 실 서비스에 적용하고자 한다면 반드시 검증 후 진행하셔야 합니다. ^^&lt;/p&gt;</description>
    </item>
    <item>
      <title>MariaDB의 FederatedX 엔진을 활용한 9억 데이터 이관기</title>
      <link>//localhost:1313/2014/12/how-to-migrate-100million-with-federatedx/</link>
      <pubDate>Sat, 27 Dec 2014 14:16:23 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2014/12/how-to-migrate-100million-with-federatedx/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;대용량 로그 테이블은 때로는 서비스에 지대한 영향을 미치기도 합니다. 게다가 이 테이블을 파티셔닝 구성을 해야하는데, 이를 서비스 운영 중인 상태에서 마스터 장비에서 Import하는 것은 사실 대단히 위험한 시도이기도 하죠.&lt;/p&gt;&#xA;&lt;p&gt;이런 상황에서 얼마 전 FederatedX엔진을 활용하여 9억 데이터를 이관한 사례가 있는데, 이에 대해 공유하도록 하겠습니다. ^^&lt;/p&gt;&#xA;&lt;h1 id=&#34;goal&#34;&gt;Goal&lt;/h1&gt;&#xA;&lt;p&gt;9억 건의 데이터를 Import하는 동안 &lt;strong&gt;서비스에는 어떠한 영향도 없어야 하며&lt;/strong&gt;, 구성 후 &lt;strong&gt;어플리케이션 적용 전까지 데이터가 정상적으로 동기화&lt;/strong&gt;되어야 합니다.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;데이터 이동하는 동안 기존 서비스 영향 최소화 및 문제 발생 시 빠른 원복&lt;/li&gt;&#xA;&lt;li&gt;데이터 구성 후 어플리케이션 코드 배포 전까지 데이터 동기화&lt;/li&gt;&#xA;&lt;li&gt;데이터 보관 주기 정책에 따른 유연한 대처&lt;br&gt;&#xA;현재는 삭제 주기가 없으나, 추후 정책에 따라 변경 가능&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;let-me-see&#34;&gt;Let me SEE..&lt;/h1&gt;&#xA;&lt;p&gt;가야할 골이 정해졌으니.. 현재 상황에 대해서 분석을 해봐야겠죠. ㅎㅎ 다음은 DB 사용 현황에 대한 내용입니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MariaDB의 FederatedX를 소개합니다.</title>
      <link>//localhost:1313/2014/12/let-me-introduce-federatedx/</link>
      <pubDate>Fri, 05 Dec 2014 13:53:39 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2014/12/let-me-introduce-federatedx/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL에는 Federated라는 스토리지 엔진이 있는데, 이는 원격의 테이블에 접근하여 제어하기 위한 용도로 사용됩니다.  얼마 전 이 엔진과 관련하여 재미있는 테스트를 하였는데, 이 내용을 소개하기에 앞서서 간단하게 정리해보도록 하겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;features&#34;&gt;Features&lt;/h1&gt;&#xA;&lt;p&gt;FederatedX는 사실 MariaDB에서 Federated 엔진을 의미하는데, 이를 다른 이름으로 구분하는 것은 사실 더욱 확장된 기능을 가지기 때문입니다.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;원격 서버 접근&lt;/strong&gt;&lt;br&gt;&#xA;원격에 있는 테이블을 로컬에 있는 것처럼 사용&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;트랜잭션&lt;/strong&gt;&lt;br&gt;&#xA;2-Phase Commit 형태로 데이터의 일관성을 유지&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;파티셔닝&lt;/strong&gt;&lt;br&gt;&#xA;각 파티셔닝 별로 다른 원격 테이블 참조 가능&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;usage&#34;&gt;Usage&lt;/h1&gt;&#xA;&lt;p&gt;FederatedX 스토리지 엔진은 MariaDB에서는 기본적으로는 활성화되어 있습니다. MySQL에서는 별도의 옵션을 줘야만 활성화되는 것과는 다른 측면이죠.&lt;/p&gt;</description>
    </item>
    <item>
      <title>TokuDB? Fractal Index에 대해 알아보아요~!</title>
      <link>//localhost:1313/2014/05/fractal-index-in-tokudb/</link>
      <pubDate>Thu, 29 May 2014 14:14:11 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2014/05/fractal-index-in-tokudb/</guid>
      <description>&lt;p&gt;이 글은 제가 MySQL Power Group에 예전에 포스팅한 자료입니다.&lt;br&gt;&#xA;참고 : &lt;a href=&#34;http://cafe.naver.com/mysqlpg/189&#34;&gt;http://cafe.naver.com/mysqlpg/189&lt;/a&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;과거와는 다르게 데이터 사이즈가 비약적으로 커지고 있습니다. 특히, 최근 들어 SNS 서비스가 성황을 이루면서, 개인화된 데이터는 날이 갈수록 기하 급수적으로 늘어나고 있습니다. 최근 Fratical Index 기반의 TokuDB가 오픈 소스로 풀리면서 재조명을 받고 있는데, 이에 대해서 간단하게 설명해보도록 하겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;b-tree&#34;&gt;&lt;code&gt;B-Tree&lt;/code&gt;?&lt;/h1&gt;&#xA;&lt;p&gt;TokuDB에 논하기에 앞서, 전통적인 트리 구조인 &lt;code&gt;B-Tree&lt;/code&gt;에 대해 알아보도록 하죠.&lt;/p&gt;&#xA;&lt;p&gt;일반적으로 RDBMS에서 인덱스는 대부분 &lt;code&gt;B-Tree&lt;/code&gt;기반으로 동작하는데, 크게는 &lt;code&gt;Internal Node&lt;/code&gt;와 &lt;code&gt;Leaf Node&lt;/code&gt;로 나뉩니다. &lt;strong&gt;Internal Node는 데이터를 어느 방향(작으면 왼쪽, 크거나 같으면 오른쪽)으로 보낼 지 결정하는 Pivot과 다음 Pivot의 위치를 알려주는 포인터로 구성&lt;/strong&gt;됩니다. Internal Node의 가장 마지막 포인터는 Leaf Node를 향하는데, &lt;strong&gt;Leaf Node에는 보통은 데이터가 저장&lt;/strong&gt;이 되죠.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL의 User Level Lock를 활용한다면?</title>
      <link>//localhost:1313/2013/12/mysql-user-level-lock/</link>
      <pubDate>Mon, 02 Dec 2013 02:13:40 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2013/12/mysql-user-level-lock/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;DB에는 크게는 두 가지 타입의 Lock이 있습니다. Table Level Lock, Row Level Lock.. 두 가지 타입의 Lock은 RDBMS에서 대표적인 Lock이라고 지칭할 수 있습니다.&lt;/p&gt;&#xA;&lt;p&gt;Table Level Lock은 데이터 변경 시 테이블 자체를 Lock을 걸어 안전하게 데이터를 변경하는 방식이고, Row Level Lock은 변경되는 칼럼의 Row에만 Lock을 걸어서 데이터를 조작하는 방식입니다. 일반적인 상황에서는 두 가지의 Lock만으로도 충분히 다양한 사용자의 요구사항을 충족할 수가 있습니다.&lt;/p&gt;&#xA;&lt;p&gt;그러나, 테이블 파티셔닝을 하는 경우나, 혹은 다양한 서버에 데이터가 분산 저장되는 경우 DB 내적인 제약사항 혹은 데이터 공간 자체의 한계로 인해 상황에 따라 더욱 확장된 Lock이 필요한 경우가 있습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>InnoDB에서 Auto_Increment를 맹신하지 말자.</title>
      <link>//localhost:1313/2013/02/mysql-innodb-auto-increment/</link>
      <pubDate>Sun, 17 Feb 2013 15:01:55 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2013/02/mysql-innodb-auto-increment/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL에서는 시퀀스 개념이 없지만, 테이블 단위로 움직이는 Auto_Increment라는 강력한 기능이 있습니다. Auto_Increment 속성은 숫자 형 Primary Key를 생성하는 데 많이 사용됩니다.&lt;/p&gt;&#xA;&lt;p&gt;특히나 InnoDB 경우에는 Primary Key 사이즈가 전체 인덱스 사이즈에 직접적인 영향을 미치기 때문에, 저도 테이블 설계에 많이 권고하는 사항이기도 합니다.&lt;/p&gt;&#xA;&lt;p&gt;그러나 InnoDB에서 Auto_Increment가 동작하는 방식을 정확하게 알지 못하고 사용하면, 대형 장애 상황으로도 치닫을 수 있습니다.&lt;/p&gt;&#xA;&lt;p&gt;오늘은 간단한 사례를 바탕으로 관련 내용을 공유할까 합니다. ^^&lt;/p&gt;&#xA;&lt;h1 id=&#34;auto_increment-in-innodb&#34;&gt;Auto_Increment In InnoDB&lt;/h1&gt;&#xA;&lt;p&gt;Auto_Increment는 스토리지 엔진 별로 다르게 동작합니다. 파일 기반의 스토리지 엔진인 MyISAM 경우에는 현재 Auto_Increment값이 파일에 일일이 기록되는 방식으로 관리됩니다. 그러나 메모리 기반의 스토리지 엔진인 InnoDB에서는 조금 다른 방식으로 관리됩니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MariaDB/Galera Cluster 기술 노트!!</title>
      <link>//localhost:1313/2012/09/mariadb-galera-cluster/</link>
      <pubDate>Wed, 12 Sep 2012 06:38:23 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/09/mariadb-galera-cluster/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MariaDB에서 MariaDB/Galera Cluster 제품군을 새롭게 출시하였습니다.MariaDB/Galera는 MariaDB의 &lt;strong&gt;Synchronous 방식으로 동작하는 다중 마스터 클러스터&lt;/strong&gt;입니다.&lt;/p&gt;&#xA;&lt;p&gt;MariaDB/Galera Cluster은 Galera 라이브러리를 사용하여 노드 간 데이터 복제를 수행합니다. 물론 아직은 Alpha 버전으로 발표되기는 했지만, 조만간 안정적인 버전이 릴리즈 되면 상당한 물건이 될만한 놈입니다.&lt;/p&gt;&#xA;&lt;p&gt;오늘은 이에 관해 간단하게 리뷰를 하겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;feature--benefits&#34;&gt;Feature &amp;amp; Benefits&lt;/h1&gt;&#xA;&lt;p&gt;먼저 MariaDB/Galera Cluster의 특징은 다음과 같이 몇 가지로 나눠볼 수 있습니다.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Synchronous 방식으로 노드 간 데이터 복제&lt;/li&gt;&#xA;&lt;li&gt;Active-Active 방식의 다중 마스터 구성 모든 노드에서 읽기/쓰기가 가능&lt;/li&gt;&#xA;&lt;li&gt;클러스터 내 노드 자동 컨트롤 특정 노드 장애 시 자동으로 해당 노드 제거&lt;/li&gt;&#xA;&lt;li&gt;자동으로 신규 노드 추가&lt;/li&gt;&#xA;&lt;li&gt;완벽한 병렬적으로 데이터를 행단위로 복제&lt;/li&gt;&#xA;&lt;li&gt;기존의 MySQL 클라이언트 방식으로 동작&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;//localhost:1313/img/2012/09/cluster-diagram1.png&#34; alt=&#34;cluster-diagram1&#34;&gt;&#xA;출처 : &lt;a href=&#34;http://www.percona.com/doc/percona-xtradb-cluster/_images/cluster-diagram1.png&#34;&gt;http://www.percona.com/doc/percona-xtradb-cluster/_images/cluster-diagram1.png&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL 성능 최적화를 위한 몇 가지 팁!!</title>
      <link>//localhost:1313/2012/09/mysql-tuning/</link>
      <pubDate>Tue, 11 Sep 2012 07:25:17 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/09/mysql-tuning/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;트위터에서 우연히 성능 관련 가벼운 아는척(?)을 시작으로 일이 커지고 말았네요. ^^;; 성능 관련된 트윗을 보고 몇 가지 코멘트만 한다는 것이.. ㅎㄷㄷ한 멘션이 되고 말았습니다.&lt;/p&gt;&#xA;&lt;p&gt;그래서 부족하나마, MySQL 성능 최적화 시 본능적으로 이행하는 몇 가지를 정리해보겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;global-variable&#34;&gt;Global Variable&lt;/h1&gt;&#xA;&lt;p&gt;성능과 연관이 되는 몇 가지 파라메터 변수는 반드시 체크를 하시기 바랍니다. MySQL에서 주로 InnoDB를 사용하는 상태라면 innodb_buffer_pool_size, innodb_log_file_size,  innodb_log_files_in_group, innodb_flush_log_at_trx_commit, innodb_doublewrite, sync_binlog 정도가 성능에 직접적인 영향을 미치는 요소라고 볼 수 있습니다.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;innodb_buffer_pool_size&lt;/strong&gt;&lt;br&gt;&#xA;InnoDB에게 할당하는 버퍼 사이즈로 50~60%가 적당하며, 지나치게 많이 할당하면 Swap이 발생할 수 있습니다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;innodb_log_file_size&lt;/strong&gt;&lt;br&gt;&#xA;트랜잭션 로그를 기록하는 파일 사이즈이며, 128MB ~ 256MB가 적당합니다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;innodb_log_files_in_group&lt;/strong&gt;&lt;br&gt;&#xA;트랜잭션 로그 파일 개수로  3개로 설정합니다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;innodb_flush_log_at_trx_commit&lt;/strong&gt;&lt;br&gt;&#xA;서비스 정책에 따라 다르게 설정하겠지만, 저는 일반적으로 2값으로 세팅합니다.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;0: 초당 1회씩 트랜잭션 로그 파일(innodb_log_file)에 기록&lt;/li&gt;&#xA;&lt;li&gt;1: 트랜잭션 커밋 시 로그 파일과 데이터 파일에 기록&lt;/li&gt;&#xA;&lt;li&gt;2: 트랜잭션 커밋 시 로그 파일에만 기록, 매초 데이터 파일에 기록&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;innodb_doublewrite&lt;/strong&gt;&lt;br&gt;&#xA;이중으로 쓰기 버퍼를 사용하는지 여부를 설정하는 변수로 활성화 시 innodb_doublewrite 공간에 기록 후 데이터 저장합니다. 저는 활성화합니다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;sync_binlog&lt;/strong&gt;&lt;br&gt;&#xA;트랜잭션 커밋 시 바이너리 로그에 기록할 것인지에 관한 설정이며, 저는 비활성 처리합니다.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;참고로 innodb_buffer_pool_size를 32G 메모리 서버에서 24G로 할당한 적이 있는데, SQL트래픽이 많아짐에 따라 Swap이 발생하더군요. 버퍼풀에는 대략 한 시간 정도 Active한 데이터와 인덱스를 담을 수 있는 사이징이라면 적절할 것 같습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Maria 2탄 – 진화하는 Maria, 함께하는 MySQL!!</title>
      <link>//localhost:1313/2012/07/improve-mariadb-mysql/</link>
      <pubDate>Tue, 17 Jul 2012 02:13:57 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/07/improve-mariadb-mysql/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL 오픈 소스 진영은 더이상 단순 데이터 처리에만 강한 DBMS이기를 거부합니다. 이제는 대용량 처리에 적합하도록 탈바꿈 중입니다.&lt;/p&gt;&#xA;&lt;p&gt;지금까지 MySQL에서는 단일 쓰레드로 Nested Loop 방식으로 쿼리를 처리하였기 때문에, 조인 건 수가 대형화될 수록 성능이 급속도로 악화되었습니다.&lt;/p&gt;&#xA;&lt;p&gt;MariaDB는 5.3버전부터 DB 엔진과 스토리지 엔진 간의 데이터 전송이 개선되었고, 조인 시 추가적인 블록 기반의 조인 알고리즘을 제공합니다. 물론 MySQL도 5.6버전부터는 관련 기능을 어느정도 지원합니다.&lt;/p&gt;&#xA;&lt;p&gt;변화하는 MariaDB에 대해 몇 가지 소개하도록 하겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;disk-access-optimization&#34;&gt;Disk access optimization&lt;/h1&gt;&#xA;&lt;h3 id=&#34;1-index-condition-pushdown&#34;&gt;1) Index Condition Pushdown&lt;/h3&gt;&#xA;&lt;p&gt;MySQL/MariaDB는 구조적으로 DB 엔진과 스토리지 엔진 역할이 명확하게 구분됩니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Maria 1탄 – MySQL의 쌍둥이 형제 MariaDB를 소개합니다.</title>
      <link>//localhost:1313/2012/06/let-me-introduce-mariadb/</link>
      <pubDate>Mon, 18 Jun 2012 10:27:47 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/06/let-me-introduce-mariadb/</guid>
      <description>&lt;h1 id=&#34;mariadb란&#34;&gt;MariaDB란?&lt;/h1&gt;&#xA;&lt;p&gt;MySQL이 Sun Microsystems로 넘어가면서 당시 MySQL AB 출신들이 따로 나와서 MySQL을 기반으로 한 다른 오픈 소스 기반의 DBMS를 배포했다고 합니다. 바로 MariaDB가 그것이며 MySQL과 유전 정보를 그대로 고수한 진짜 오픈 소스 기반의 DBMS입니다.&lt;/p&gt;&#xA;&lt;p&gt;현재 Monty Program AB와 MariaDB Community에서 개발하고 있으며, MySQL과 기본적으로 구조 및 사용 방법 등 모두 동일합니다. (동일 소스에서 개발되고 있으니 당연한 말입니다.)&lt;/p&gt;&#xA;&lt;p&gt;Monty Program AB에 따르면 많은 기능들이 MariaDB에서 먼저 구현을 하고 그 후 MySQL에도 반영이 된다고 하는데, 마치 CentOS와 Redhat 리눅스 관계 같다는 생각이 듭니다.^^&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
