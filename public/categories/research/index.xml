<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research on gywn&#39;s tech</title>
    <link>//localhost:1313/categories/research/</link>
    <description>Recent content in Research on gywn&#39;s tech</description>
    <generator>Hugo</generator>
    <language>en</language>
    <managingEditor>gywndi@gmail.com (gywndi)</managingEditor>
    <webMaster>gywndi@gmail.com (gywndi)</webMaster>
    <lastBuildDate>Tue, 19 Aug 2025 20:14:31 +0900</lastBuildDate>
    <atom:link href="//localhost:1313/categories/research/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Apache Ignite로 분산 캐시 만들어보고 싶어요 (1탄)</title>
      <link>//localhost:1313/2023/10/apache-ignite-as-cache-cluster/</link>
      <pubDate>Tue, 10 Oct 2023 07:10:35 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2023/10/apache-ignite-as-cache-cluster/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;안녕하세요. 벌써 일년이 넘는 시간동안 포스팅을 하지 않았네요.&lt;/p&gt;&#xA;&lt;p&gt;그동안 업무적으로 많은 변화도 있던 격동의 시기였던지라, 제 삶의 가장 중요한 요소 중 하나라 생각하던 공유의 가치를 그만 간과하고 말았네요. 물론 포스팅을 멈춘 시간동안 놀지 않고 많은 경험을 쌓아보았습니다.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;오늘은 그중 하나, 인메모리 데이터베이스인 Apache Ignite에 대해 이야기를 해보고자 합니다.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;apache-ignite&#34;&gt;Apache Ignite?&lt;/h1&gt;&#xA;&lt;p&gt;이미 많은 분들이 Ignite 를 사용해보셨을 수도 있겠습니다만, 저는 DBA로 일을 하면서도 늘 제대로된 캐시 용도로 써보고 싶었던 분산 인메모리 데이터베이스가 Apache Ignite입니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[MySQL] Online Alter에도 헛점은 있더구나 – gdb, mysqld-debug 활용 사례</title>
      <link>//localhost:1313/2018/10/online-alter-for-varchar/</link>
      <pubDate>Fri, 12 Oct 2018 00:00:52 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2018/10/online-alter-for-varchar/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL에서도 5.6부터는 온라인 Alter 기능이 상당부분 제공되기 시작했습니다. 인덱스과 칼럼 추가/삭제 뿐만 아니라, varchar 경우에는 부분적으로 칼럼 확장이 서비스 중단없이 가능한 것이죠. 물론 오라클 유저들에게는 당연한 오퍼레이션들이, MySQL에서는 두손들고 운동장 20바퀴 돌 정도로 기뻐할만한 기능들입니다. 물론, 대부분의 DDL을 테이블 잠금을 걸고 수행하던 5.5 시절에도 online alter를 위해 트리거 기반의 pt-online-schema-change 툴을 많이들 사용했었기에.. 서비스 중단이 반드시 필요하지는 않았지만요. (&lt;a href=&#34;//localhost:1313/2017/08/small-talk-pt-osc/&#34;&gt;소소한 데이터 이야기 – pt-online-schema-change&lt;/a&gt;)&lt;/p&gt;&#xA;&lt;p&gt;아무튼 이렇게 online alter가 대거 지원하는 상황 속에서, MySQL의 메뉴얼과는 다르게 잘못 동작하는 부분이 있었는데, 이 원인을 찾아내기 위해서는 MySQL 내부적으로 어떻게 동작을 하는지 알아내기 위해 며칠 우물을 신나게 파보았습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>PMM 이야기 1편 – INTRO</title>
      <link>//localhost:1313/2018/03/pmm-intro/</link>
      <pubDate>Sat, 03 Mar 2018 17:33:28 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2018/03/pmm-intro/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;정말 오랜만에 글을 써봅니다. 은행이 오픈한지도 어언 8개월째를 훌쩍 접어들었네요. 여전히 MySQL 서버군에는 이렇다할 장애 없이, 무난(?)하게 하루하루를 지내고 있습니다.. (아.. 그렇다고 놀고만 있지는 않았어요!!)&lt;/p&gt;&#xA;&lt;p&gt;사실 그동안의 경험과 삽질을 바탕으로, 필요성을 느꼈던 다양한 부분을 중앙 매니저에 최대한 녹여보았고, 그 집대성의 결과가 지금 뱅킹 MySQL시스템입니다. MHA 관리, 스키마 관리, 파티션 관리, 패스워드 관리, 백업/복구 관리..아.. 또 뭐있더라.. -_-;; 암튼, 귀찮은 모든 것들은 최대한 구현을 해놓았지요.&lt;/p&gt;&#xA;&lt;p&gt;그러나, 예전부터 늘 부족하다고 생각해왔던 한가지 분야가 있는데.. 그것은 바로 모니터링입니다. 시스템에 대한 가장 정확한 최신 정보는 바로 모니터링 지표입니다. 만약, 제대로된 모니터링 시스템 환경 속에서, 실제 서비스의 영속성과 시스템의 매니지먼트를 &lt;strong&gt;모니터링 지표&lt;/strong&gt;를 통해서 제대로된 &lt;strong&gt;에코 시스템&lt;/strong&gt;을 구축할 수 있다면? 등골이 오싹할 정도의 선순환 작용으로 엄청 견고한 시스템을 구축할 수 있겠죠.&lt;/p&gt;</description>
    </item>
    <item>
      <title>JDBC의 autoReconnect 파라메터가 저지른 일!</title>
      <link>//localhost:1313/2017/10/jdbc-insane-autoreconnect/</link>
      <pubDate>Tue, 31 Oct 2017 00:00:00 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2017/10/jdbc-insane-autoreconnect/</guid>
      <description>&lt;p&gt;세상에 말도 안되는 일이 일어났습니다.&lt;/p&gt;&#xA;&lt;p&gt;서비스가 정상적으로 동작하기 위해서는, 아무래도 데이터베이스가 필수인데.. 이 데이터베이스로부터 쉽게 데이터를 주고받을 수 있게 디비별/언어별 중간 역할을 해주는 것이 바로 Driver입니다.&lt;/p&gt;&#xA;&lt;p&gt;MySQL역시 자바에서 원활하게 데이터 처리를 수행할 수 있도록 &lt;code&gt;connector/j&lt;/code&gt;라는 녀석을 Oracle에서 배포를 하는데.. 오늘은 이 녀석이 제공해주는 기능인 &lt;code&gt;autoReconnect&lt;/code&gt; 파라메터가 저지르는 일에 대해서 얘기를 해보고자 합니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;autoreconnect는-무슨-일을-하는가&#34;&gt;autoReconnect는 무슨 일을 하는가?&lt;/h1&gt;&#xA;&lt;p&gt;파라메터 이름 그대로.. 자동으로 커넥션을 다시 맺어준다는 의미입니다. 데이터베이스 역시 서버로 구동하는 프로그램의 한 축이기에.. 클라이언트가 맺은 커넥션이 절대 끊어지지 않는다고 보장할 수 없습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL_5.7의 n-gram 전문 검색을 이상하지 않게 써보아요.</title>
      <link>//localhost:1313/2017/04/mysql_57-ngram-ft-se/</link>
      <pubDate>Tue, 18 Apr 2017 23:47:31 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2017/04/mysql_57-ngram-ft-se/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL5.6부터는 InnoDB에서도 전문검색이 가능하기는 하였습니다만.. 아쉽게도 여전히 공백 기준으로 단어들이 파싱이 되는 &lt;code&gt;MeCab Full-Text Parser Plugin&lt;/code&gt; 방식으로 동작합니다. 즉, 한국말처럼 공백만으로 단어를 파싱할 수 없는 언어의 경우에는 크게 매력적이지는 않습니다. &lt;strong&gt;InnoDB에서 전문검색 인덱싱이 가능하다는 것은 Transaction이 전제로 이루어지는 것이라고 볼 수 있기에.. 리플리케이션 및 시점 백업/복구 측면에서는 혁신&lt;/strong&gt;으로 볼 수 있습니다.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;반드시 Limit로 끊어서 가져오고자 한다면, &amp;lsquo;Order By&amp;rsquo;로 정렬을 하세요~ 이 관련해 버그가 있고 조만간 픽스될 예정이기는 합니다. (n-gram 처리 시 스토리지 엔진에서 limit이 영향을 미쳐 제대로된 결과 도출 혹은 최악의 경우 크래시까지 발생할 수 있어요.)&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>세상만사 귀찮은 MySQL DBA를 위한 자동 복구 시나리오</title>
      <link>//localhost:1313/2017/01/automated-recovery-scenarios-for-lazy-mysql-dba/</link>
      <pubDate>Mon, 23 Jan 2017 14:10:02 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2017/01/automated-recovery-scenarios-for-lazy-mysql-dba/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;안녕하세요. 요새 창고 대방출! 그동안 미뤄 두었던 얘기들을 연달아 공유합니다. (마스터 스크립트를 만들어야하는 수고를 덜기 위해.. 해당 스크립트 제거 및 스크립트 수정하였습니다.)&lt;/p&gt;&#xA;&lt;p&gt;MySQL을 사용하는 이상, 리플리케이션 활용에서 벗어나기 쉽지 않은데요. 그 말은 곧 다수의 동일한 데이터를 가진 여러개의 서버를 운영관리 해야한다는 말과 같고.. 장비가 많아진다는 것은 그만큼 데이터 복구가 많다는 이야기이기도 하지요. 특히나 샤딩 환경으로 데이터 폭증을 대비해두었다면 더욱 그렇습니다.&lt;/p&gt;&#xA;&lt;p&gt;게다가 복구 시 새벽 백업을 사용한다는 말은 곧 새벽 이후로 저장이된 변경 이력을 일괄 적용을 해야하고.. 이 내용이 많으면 데이터 동기화 시간도 적지않게 소모되고.. (횡설수설~)&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL에서 파티션 일부를 다른 파티션 테이블로 옮겨보기</title>
      <link>//localhost:1313/2017/01/how_to_move_partition_data_to_another/</link>
      <pubDate>Fri, 20 Jan 2017 04:24:56 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2017/01/how_to_move_partition_data_to_another/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;한동안 운영에 치여, 문서를 못봤더니, 재미난 사례를 많이 놓친듯.&lt;br&gt;&#xA;그래서 여기저기 떠도는 문서 중 재미난 사례 하나를 내 입맛에 맞게 샘플을 변경해서 공유해봅니다.&lt;br&gt;&#xA;(영혼없이 붙여넣기만 해도 알아보기 쉽게 ㅋㅋ)&lt;/p&gt;&#xA;&lt;h1 id=&#34;preview&#34;&gt;Preview&lt;/h1&gt;&#xA;&lt;p&gt;파티셔닝 특정 부분을 다른 테이블 혹은 파티셔닝 일부로 넘기는 방안에 대한 것인데..&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;//localhost:1313/img/2017/01/move-partition-data-file.png&#34; alt=&#34;move-partition-data-file&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;하단 포스팅 내용 중 미흡한 부분을 보완해서 정리해본 것입니다&lt;br&gt;&#xA;&lt;a href=&#34;https://dzone.com/articles/how-to-move-a-mysql-partition-from-one-table-to-an&#34;&gt;https://dzone.com/articles/how-to-move-a-mysql-partition-from-one-table-to-an&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;generate-test-data&#34;&gt;Generate Test Data&lt;/h1&gt;&#xA;&lt;p&gt;먼저 테스트 데이터를 생성해야할테니..&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f_tb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seq&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;bigint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;not&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;0&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;regdate&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;not&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cont&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;not&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;primary&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;seq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;regdate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;engine&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;innodb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;collate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;utf8_unicode_ci&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/*!50500 partition by range columns(regdate)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;  (partition p09 values less than (&amp;#39;2016-10-01&amp;#39;),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;   partition p10 values less than (&amp;#39;2016-11-01&amp;#39;),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;   partition p11 values less than (&amp;#39;2016-12-01&amp;#39;),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;   partition p12 values less than (&amp;#39;2017-01-01&amp;#39;)) */&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;아래처럼 테스트로 사용할 데이터를 간단하게 생성해봅니다. 2017-01-01 기점으로 랜덤하게 120일 사이 일을 빼서 마치 파티셔닝 테이블이 관리된 것처럼 데이터를 밀어넣는 것이죠.&lt;/p&gt;</description>
    </item>
    <item>
      <title>PowerDNS와 MySQL로 DNS를 해보고 싶어요~</title>
      <link>//localhost:1313/2017/01/install_powerdns_with_mysql_backend/</link>
      <pubDate>Tue, 17 Jan 2017 13:54:29 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2017/01/install_powerdns_with_mysql_backend/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;PowerDNS란 범용적(?)으로 사용되는 오픈소스 기반의 DNS서버이고, 다양한 백엔드를 지원하는 멋진(?) DNS 이기도 합니다. 얼마전, 이 관련되어 간단한 사례에 대해 세미나를 진행을 하였고, 이 구성에 대한 설명이 미흡하여 간단하게 정리해봅니다. ^^&lt;/p&gt;&#xA;&lt;h1 id=&#34;install-powerdns&#34;&gt;Install PowerDNS&lt;/h1&gt;&#xA;&lt;p&gt;CentOS 6.7 버전에서 구성을 하였고, 실제 설치 작업에는 아래와 같이 같단합니다.&lt;br&gt;&#xA;(참고 : &lt;a href=&#34;https://doc.powerdns.com/md/authoritative/installation/#binary-packages&#34;&gt;https://doc.powerdns.com/md/authoritative/installation/#binary-packages&lt;/a&gt;)&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ yum install pdns&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ yum install pdns-backend-mysql&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;(단, 여기서 MySQL 은 이미 구성되어 있다는 가정하에 진행합니다.)&lt;/p&gt;&#xA;&lt;h1 id=&#34;configuration&#34;&gt;Configuration&lt;/h1&gt;&#xA;&lt;p&gt;자~ 이제 DNS 데몬을 설치하였으니..(두줄에.. 끝? -_-;; 헐~)&lt;/p&gt;</description>
    </item>
    <item>
      <title>파티션 제약 극복기! 유니크한 토큰 값을 만들어보자!</title>
      <link>//localhost:1313/2015/07/generate-unique-token-on-partitioning-table/</link>
      <pubDate>Fri, 03 Jul 2015 14:15:42 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2015/07/generate-unique-token-on-partitioning-table/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL에는 날짜 별 데이터 관리를 위해 파티셔닝이라는 좋은 기능(?)을 5.1버전부터 무료(!)로 제공합니다. 일정 시간 지난 후 불필요한 데이터는 간단하게 해당 파티셔닝을 제거하면, 굳이 DELETE 쿼리로 인한 오버헤드를 방지할 수 있죠.&lt;/p&gt;&#xA;&lt;p&gt;그러나, 파티셔닝 적용 시, **&amp;ldquo;파티셔닝 키는 반드시 PK에 포함되어야 한다&amp;rdquo;, &amp;ldquo;추가 제약조건(유니크 속성)을 부여할 수 없다&amp;rdquo;**라는 대표적인 제약 조건으로 인하여, 유니크 속성을 가지는 데이터를 파티셔닝 적용이 불가한 경우가 있는데.. 이것을 해결할 수 있는 간단한 트릭을 이 자리에서 설명하고자 합니다. ^^&lt;/p&gt;</description>
    </item>
    <item>
      <title>InnoDB의 Adaptive Hash Index로 쿼리 성능에 날개를 달아보자!!</title>
      <link>//localhost:1313/2015/01/innodb-adaptive-hash-index/</link>
      <pubDate>Thu, 08 Jan 2015 13:28:02 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2015/01/innodb-adaptive-hash-index/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL과 같은 RDBMS에서 대표적으로 가장 많이 사용되는 자료 구조는 B-Tree입니다. 데이터 사이즈가 아무리 커져도 특정 데이터 접근에 소요되는 비용이 크게 증가되지 않기 때문에 어느정도 예상할 수 있는 퍼포먼스를 제공할 수 있기 때문이죠. 그치만 상황에 따라서, B-Tree 사용에 따른 잠금 현상으로 최대의 퍼포먼스를 발휘하지 못하는 경우도 있습니다.&lt;/p&gt;&#xA;&lt;p&gt;이에 대한 해결책으로 InnoDB에는 Adaptive Hash Index 기능이 있는데, 어떤 상황에서 효과가 있고 사용 시 반드시 주의를 해야할 부분에 대해서 정리해보겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;innodb-b-tree-index&#34;&gt;InnoDB B-Tree Index?&lt;/h1&gt;&#xA;&lt;p&gt;소개하기에 앞서서 먼저 InnoDB에서 B-Tree가 어떠한 방식으로 활용되는 지 알아볼까요?&lt;/p&gt;</description>
    </item>
    <item>
      <title>MariaDB의 FederatedX 엔진으로 데이터를 주물러보자.</title>
      <link>//localhost:1313/2014/12/mariadb-federatedx-usage/</link>
      <pubDate>Tue, 30 Dec 2014 13:12:02 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2014/12/mariadb-federatedx-usage/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;FederatedX는 MariaDB에서 제공하는 확장된 기능의 Federated이며, 기본적으로 MariaDB에서는 별다른 옵션 없이 사용할 수 있습니다.&lt;/p&gt;&#xA;&lt;p&gt;바로 이전 포스팅(&lt;a href=&#34;//localhost:1313/2014/12/how-to-migrate-100million-with-federatedx/&#34;&gt;MariaDB의 FederatedX 엔진을 활용한 9억 데이터 이관기&lt;/a&gt;)에서는 이 FederatedX 엔진을 활용하여 대용량 테이블을 서비스에 큰 지장없이 이관을 했던 사례에 대해서 정리를 했었는데요. 이 경험을 바탕으로 서비스에서 조금 더 유용하게 활용할 수 있을 방안에 대해서 상상(?)을 해보았습니다.&lt;/p&gt;&#xA;&lt;p&gt;즉, 지금부터는 FederatedX 엔진 관련된 테스트를 바탕으로 정리하는 내용이오니, 만약 실 서비스에 적용하고자 한다면 반드시 검증 후 진행하셔야 합니다. ^^&lt;/p&gt;</description>
    </item>
    <item>
      <title>TokuDB? Fractal Index에 대해 알아보아요~!</title>
      <link>//localhost:1313/2014/05/fractal-index-in-tokudb/</link>
      <pubDate>Thu, 29 May 2014 14:14:11 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2014/05/fractal-index-in-tokudb/</guid>
      <description>&lt;p&gt;이 글은 제가 MySQL Power Group에 예전에 포스팅한 자료입니다.&lt;br&gt;&#xA;참고 : &lt;a href=&#34;http://cafe.naver.com/mysqlpg/189&#34;&gt;http://cafe.naver.com/mysqlpg/189&lt;/a&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;과거와는 다르게 데이터 사이즈가 비약적으로 커지고 있습니다. 특히, 최근 들어 SNS 서비스가 성황을 이루면서, 개인화된 데이터는 날이 갈수록 기하 급수적으로 늘어나고 있습니다. 최근 Fratical Index 기반의 TokuDB가 오픈 소스로 풀리면서 재조명을 받고 있는데, 이에 대해서 간단하게 설명해보도록 하겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;b-tree&#34;&gt;&lt;code&gt;B-Tree&lt;/code&gt;?&lt;/h1&gt;&#xA;&lt;p&gt;TokuDB에 논하기에 앞서, 전통적인 트리 구조인 &lt;code&gt;B-Tree&lt;/code&gt;에 대해 알아보도록 하죠.&lt;/p&gt;&#xA;&lt;p&gt;일반적으로 RDBMS에서 인덱스는 대부분 &lt;code&gt;B-Tree&lt;/code&gt;기반으로 동작하는데, 크게는 &lt;code&gt;Internal Node&lt;/code&gt;와 &lt;code&gt;Leaf Node&lt;/code&gt;로 나뉩니다. &lt;strong&gt;Internal Node는 데이터를 어느 방향(작으면 왼쪽, 크거나 같으면 오른쪽)으로 보낼 지 결정하는 Pivot과 다음 Pivot의 위치를 알려주는 포인터로 구성&lt;/strong&gt;됩니다. Internal Node의 가장 마지막 포인터는 Leaf Node를 향하는데, &lt;strong&gt;Leaf Node에는 보통은 데이터가 저장&lt;/strong&gt;이 되죠.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux Hot Copy(hcp) – Snapshot Tool</title>
      <link>//localhost:1313/2013/12/let-me-know-linux-hot-backup/</link>
      <pubDate>Tue, 10 Dec 2013 03:53:02 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2013/12/let-me-know-linux-hot-backup/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;몇 달전 Linux Hot Copy(HCP) 유틸리티가 무료로 풀리면서, 고가의 스냅샷 유틸리티를 구입 없이도 얼마든지 사용할 수 있게 되었습니다. 스냅샷을 멋지게 활용할 수 있다면, 단순히 데이터 백업 뿐만 아니라 DB 시스템과 같이 복잡하게 얽혀서 구동되는 데이터도 특정 시점으로 데이터를 복사할 수 있습니다.&lt;/p&gt;&#xA;&lt;p&gt;이 경우 Linux Hot Copy(hcp)에 대해 알아보도록 하겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;feature&#34;&gt;Feature&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Point-in-Time 디스크 볼륨 스냅샷&lt;/li&gt;&#xA;&lt;li&gt;Copy on Write 방식의 Snapshot&lt;/li&gt;&#xA;&lt;li&gt;서비스 영향없이 스냅샷을 생성&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4 id=&#34;snapshot-비교&#34;&gt;&amp;lt;Snapshot 비교&amp;gt;&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Copy-on-Write&lt;/strong&gt;&lt;br&gt;&#xA;Write 시 원본 데이터 Block을 Snapshot 스토리지로 복제하는 방식으로 Snapshot 데이터 Read 시 변경되지 않은 데이터는 원본 블록에서,변경된 데이터는 Snapshot 블록에서 처리&lt;br&gt;&#xA;데이터 변경 분만 저장하므로 공간을 효율적으로 활용하나 블록 변경 시 원본 데이터와 스냅샷 데이터 양쪽 모두에서 Write이 발생&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Redirect-on-Write&lt;/strong&gt;&lt;br&gt;&#xA;Copy-on-Write와 유사하나, 원본 볼륨에 대한 Write을 별도의 공간에 저장하는 방식으로 Copy-on Write(원본 Read, 원본 Write, 스냅샷 Write)에 비해 Write이 1회만 발생하나, 스냅샷 해제 시 변경된 블록들을 원본 데이터 블록으로 Merge시켜야함&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Split mirror&lt;/strong&gt;&lt;br&gt;&#xA;원본 볼륨과 동일한 사이즈의 별도 복제 볼륨 생성하는 방식으로 데이터를 Full Copy하므로 즉시 생성이 어렵고 용량 또한 많이 필요&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;&#xA;&lt;p&gt;설치 버전을 다운로드 하기 위해서는 하단 페이지에서 등록해야하는데, 등록하게 되면 설치 바이너리를 다운로드 받을 수 있는 별도의 링크를 메일로 보내줍니다. 완벽한 오픈소스는 아닌지라.. 설치하기가 조금은 짜증이 나지만.. 일단은..뭐.. ㅎㅎ&lt;/p&gt;</description>
    </item>
    <item>
      <title>MariaDB/Galera Cluster 기술 노트!!</title>
      <link>//localhost:1313/2012/09/mariadb-galera-cluster/</link>
      <pubDate>Wed, 12 Sep 2012 06:38:23 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/09/mariadb-galera-cluster/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MariaDB에서 MariaDB/Galera Cluster 제품군을 새롭게 출시하였습니다.MariaDB/Galera는 MariaDB의 &lt;strong&gt;Synchronous 방식으로 동작하는 다중 마스터 클러스터&lt;/strong&gt;입니다.&lt;/p&gt;&#xA;&lt;p&gt;MariaDB/Galera Cluster은 Galera 라이브러리를 사용하여 노드 간 데이터 복제를 수행합니다. 물론 아직은 Alpha 버전으로 발표되기는 했지만, 조만간 안정적인 버전이 릴리즈 되면 상당한 물건이 될만한 놈입니다.&lt;/p&gt;&#xA;&lt;p&gt;오늘은 이에 관해 간단하게 리뷰를 하겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;feature--benefits&#34;&gt;Feature &amp;amp; Benefits&lt;/h1&gt;&#xA;&lt;p&gt;먼저 MariaDB/Galera Cluster의 특징은 다음과 같이 몇 가지로 나눠볼 수 있습니다.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Synchronous 방식으로 노드 간 데이터 복제&lt;/li&gt;&#xA;&lt;li&gt;Active-Active 방식의 다중 마스터 구성 모든 노드에서 읽기/쓰기가 가능&lt;/li&gt;&#xA;&lt;li&gt;클러스터 내 노드 자동 컨트롤 특정 노드 장애 시 자동으로 해당 노드 제거&lt;/li&gt;&#xA;&lt;li&gt;자동으로 신규 노드 추가&lt;/li&gt;&#xA;&lt;li&gt;완벽한 병렬적으로 데이터를 행단위로 복제&lt;/li&gt;&#xA;&lt;li&gt;기존의 MySQL 클라이언트 방식으로 동작&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;//localhost:1313/img/2012/09/cluster-diagram1.png&#34; alt=&#34;cluster-diagram1&#34;&gt;&#xA;출처 : &lt;a href=&#34;http://www.percona.com/doc/percona-xtradb-cluster/_images/cluster-diagram1.png&#34;&gt;http://www.percona.com/doc/percona-xtradb-cluster/_images/cluster-diagram1.png&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>메모리 기반 RDBMS, MemSQL을 알아봅시다</title>
      <link>//localhost:1313/2012/06/memory-based-rdbms-memsql/</link>
      <pubDate>Wed, 27 Jun 2012 10:18:56 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/06/memory-based-rdbms-memsql/</guid>
      <description>&lt;h1 id=&#34;memsql이란&#34;&gt;MemSQL이란?&lt;/h1&gt;&#xA;&lt;p&gt;MemSQL은 디스크 병목을 최소화하기 위해 만들어진 &lt;strong&gt;메모리 기반의 관계형 DBMS&lt;/strong&gt;입니다. 메모리 기반으로 데이터 처리가 이루어지기 때문에, 엄청난 속도로 Read/Write이 가능하며, 기존의 NoSQL 또는 캐시로만 가능했던 퍼포먼스 향상이 있습니다. 실제로 디스크 기반 DBMS 대비 약 30배 이상의 성능 향상이 있다고 하니, 놀라울 따름입니다.&lt;br&gt;&#xA;&lt;img src=&#34;//localhost:1313/img/2012/06/memsql-logo.png&#34; alt=&#34;memsql logo&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;최근 들어 메모리 가격이 하루가 다르게 저렴해지고 있기 때문에 메모리 사이즈를 최대한 늘려서 가격 대비 성능 비를 최대로 이끌어 내는 DB입니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;memsql-특징&#34;&gt;MemSQL 특징&lt;/h1&gt;&#xA;&lt;h3 id=&#34;1-강력한-sql기반의-통신&#34;&gt;1) 강력한 SQL기반의 통신&lt;/h3&gt;&#xA;&lt;p&gt;SQL 기반으로 통신하며, MySQL API를 따릅니다. 그렇기 때문에 기존 MySQL을 사용하는 서비스 경우 로직 변경이 불필요하다고 합니다. 하다못해 라이브러리 또한 기존 MySQL에서 사용하던 그대로 재사용해도 상관 없습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tumblr에서는 MySQL로 어떻게 대용량 데이터를 관리하였을까?</title>
      <link>//localhost:1313/2012/05/how_to_shard_big_data_in_tumblr/</link>
      <pubDate>Fri, 25 May 2012 06:17:13 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/05/how_to_shard_big_data_in_tumblr/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;//localhost:1313/2012/03/gizzard-a-library-for-creating-distributed-datastores/&#34;&gt;트위터의 새로운 분산 관리 라이브러리 Gizzard를 소개합니다.&lt;/a&gt;를 알아보던 당시 부사수 임창선님과 진행했던 또 다른 해외 사례 Tumblr를 정리해보았습니다.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.tumblr.com/&#34;&gt;Tumblr&lt;/a&gt;는 국내에서는 사용자가 많지는 않지만, Twitter 정도의 트래픽을 자랑하는 Micro Blog 서비스입니다. &lt;strong&gt;하루 평규 5억 이상의 PV&lt;/strong&gt;가 나오고, &lt;strong&gt;초당 4만 건 이상 Request&lt;/strong&gt;가 나오며, &lt;strong&gt;하루 평균 3TB 이상의 데이터&lt;/strong&gt;를 쌓는다고 하니 엄청난 서비스인 것은 틀림 없습니다.&lt;/p&gt;&#xA;&lt;p&gt;이정도 데이터를 관리하기 위해서 수 천대 이상의 서비스를 운영한다고 하는데, 데이터 관리를 MySQL을 활용하여 제공한다고 합니다. 그렇다면 MySQL로 어떻게 대용량 데이터를 멋지게 다뤘을까요?&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL에서 커버링 인덱스로 쿼리 성능을 높여보자!!</title>
      <link>//localhost:1313/2012/04/mysql-covering-index/</link>
      <pubDate>Thu, 19 Apr 2012 15:21:20 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/04/mysql-covering-index/</guid>
      <description>&lt;p&gt;안녕하세요.  오늘 짧지만 재미있는 내용을 하나 공유할까 합니다.&lt;/p&gt;&#xA;&lt;p&gt;커버링 인덱스(Covering Index)라는 내용인데, 대용량 데이터 처리 시 적절하게 커버링 인덱스를 활용하여 쿼리를 작성하면 성능을 상당 부분 높일 수 있습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;커버링-인덱스란&#34;&gt;커버링 인덱스란?&lt;/h1&gt;&#xA;&lt;p&gt;커버링 인덱스란 원하는 데이터를 인덱스에서만 추출할 수 있는 인덱스를 의미합니다. B-Tree 스캔만으로 원하는 데이터를 가져올 수 있으며, 칼럼을 읽기 위해 굳이 데이터 블록을 보지 않아도 됩니다.&lt;/p&gt;&#xA;&lt;p&gt;인덱스는 행 전체 크기보다 훨씬 작으며, 인덱스 값에 따라 정렬이 되기 때문에 Sequential Read 접근할 수 있기 때문에, 커버링 인덱스를 사용하면 결과적으로 쿼리 성능을 비약적으로 올릴 수 있습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>DB Link와 Export/Import를 활용한 데이터 이관 성능 리포트</title>
      <link>//localhost:1313/2012/04/migration_with_dblink_exp_imp/</link>
      <pubDate>Fri, 13 Apr 2012 07:41:39 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/04/migration_with_dblink_exp_imp/</guid>
      <description>&lt;p&gt;안녕하세요. 한동안 MySQL에 빠져 있다가, 최근 Oracle 데이터 이관 작업 도중 재미난 사례 공유 합니다. DB Link를 통한 CTAS(Create Table As Select)와 Export/Import를 통한 데이터 이관 비교입니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;서비스-요구-사항&#34;&gt;서비스 요구 사항&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;서비스 DBMS 버전 : Oracle 9i&lt;/li&gt;&#xA;&lt;li&gt;전체 데이터 파일 사이즈 : 120G (인덱스 포함)&lt;/li&gt;&#xA;&lt;li&gt;타겟 테이블 데이터 사이즈 : 26G (인덱스 제외)&lt;/li&gt;&#xA;&lt;li&gt;네트워크 속도 : 100Mbps (max: 12.5MB/s)&lt;/li&gt;&#xA;&lt;li&gt;일 1회 현재 서비스 데이터 동기화 수행&lt;/li&gt;&#xA;&lt;li&gt;모든 작업은 &lt;code&gt;자동화&lt;/code&gt;하여 운영 이슈 최소화&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;위 환경을 고려하였을 때, 전체 데이터 파일 Copy는 동기화 시간 및 스토리지 낭비 요소가, Archive Log 활용하기에는 운영 이슈가 존재했습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>디스크 병목 현상에 따른 DB 성능 리포트</title>
      <link>//localhost:1313/2012/03/database-performance-report-on-disk-bottleneck/</link>
      <pubDate>Sun, 18 Mar 2012 10:05:35 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/03/database-performance-report-on-disk-bottleneck/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;어느 시스템에서도 병목 현상은 어딘가에 있습니다. DBMS 또한 CPU, Memory, Disk로 구성된 하나의 시스템이기 때문에 당연히 특정 구역에서 병목현상이 발생할 수 있죠. 오늘은 Disk에서 발생하는 병목에 관해서 말씀드리겠습니다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;memory-processing&#34;&gt;Memory Processing&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;//localhost:1313/2012/03/db-performance-disk-raid-configuration/&#34;&gt;Permanent Link: 디스크 배열(RAID)에 따른 DB 성능 비교&lt;/a&gt; 에서, 메모리가 충분하면 아래와 같다는 그래프를 보여드렸습니다.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;//localhost:1313/img/2012/03/buffer_pool_12G_disk1.png&#34; alt=&#34;InnoDB Buffer Pool : 12G&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;어떤 경우든 메모리에만 연산이 가능하다면, CPU자원을 거의 활용 가능하다고 할 수 있죠. 그러나 만약 디스크 I/O가 발생하는 순간부터 CPU는 전혀 연산하지 않는 현상이 발생합니다. 바로 디스크 I/O Wait 으로 인한 시스템 병목 현상 발생입니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>디스크 배열(RAID)에 따른 DB 성능 비교</title>
      <link>//localhost:1313/2012/03/db-performance-disk-raid-configuration/</link>
      <pubDate>Sun, 18 Mar 2012 09:43:46 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/03/db-performance-disk-raid-configuration/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;MySQL DBMS 하드웨어 구성 시 어떠한 정책으로 움직이는 것이 가장 효율적일지, 메모리/디스크 설정을 변경하여 테스트를 진행하였습니다. 디스크는 RAID 레벨을 변경하였고, innodb_buffer_pool을 조정함으로써 메모리 환경을 구성하였습니다. 서비스 특성에 따라 하드웨어 구성을 달리함으로써, 장비를 더욱더 효율적으로 사용할 수 있을 것으로 기대됩니다.^^&lt;/p&gt;&#xA;&lt;h1 id=&#34;디스크배열raid란&#34;&gt;디스크배열(RAID)란?&lt;/h1&gt;&#xA;&lt;p&gt;RAID란 Redundant Array of Inexpensive Disks의 약자로 디스크를 여러장 묶어서, 데이터 중복성 및 성능 향상을 유도할 수 있는 기법입니다. RAID 기법은 참으로 많이 있으나, 일반적으로 실무에서는 RAID0, RAID1, RAID5, RAID10또는 RAID01을 많이 사용합니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>트위터의 새로운 분산 관리 라이브러리 Gizzard를 소개합니다.</title>
      <link>//localhost:1313/2012/03/gizzard-a-library-for-creating-distributed-datastores/</link>
      <pubDate>Fri, 09 Mar 2012 04:45:12 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/03/gizzard-a-library-for-creating-distributed-datastores/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;바로 이전 &lt;a href=&#34;//localhost:1313/2012/03/new-tweet-store/&#34;&gt;하루 2.5억 트윗을 저장하는 트위터의 새로운 저장 스토어&lt;/a&gt; 포스팅에서 트위터의 새로운 저장 스토어에 관해서 전반적으로 설명 드렸는데요, 이번에는 그 중 Gizzard에 관해서 심층 분석(?)을 해볼까합니다.&lt;/p&gt;&#xA;&lt;p&gt;Gizzard는 트위터에서 데이터를 분산 및 복제 관리하기 위한 자체 개발 프레임워크입니다. 클라이언트와 서버 사이에 위치하며 모든 데이터 요청을 처리하는 구조입니다. Gizzard 관련 몇 가지 키워드는 아래와 같습니다.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;분산 관리(Sharding), 분할(Partitioning), 복제(Replication)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;부하분산(Load-Balancing)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;장애복구(Fail-Over)&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;멱등성(idempotent), 가환성(commutative)&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;멱등성 : 연산을 여러 번 적용하더라도 결과가 달라지지 않는 성질&lt;/li&gt;&#xA;&lt;li&gt;가환성 : 연산의 순서를 바꾸어도 그 결과가 변하지 않는 일&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;분산-관리sharding이란&#34;&gt;분산 관리(Sharding)이란?&lt;/h1&gt;&#xA;&lt;p&gt;과거에는 서비스 성능 저하가 발생하면 곧바로 해당 서버에 CPU또는 Memory 사이즈를 증설하여 성능 이슈를 해결하였습니다. 하지만, 최근 Web 서비스에서 데이터 사이즈가 급증하여, 더 이상은 서버 성능 고도화만으로는 한계가 있기 때문에, &lt;strong&gt;다수 장비에 데이터를 분산 위치(Data Sharding)하여 데이터를 처리&lt;/strong&gt;하는 움직임이 일반화되고 있습니다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>하루 2.5억 트윗을 저장하는 트위터의 새로운 저장 스토어</title>
      <link>//localhost:1313/2012/03/new-tweet-store/</link>
      <pubDate>Thu, 08 Mar 2012 01:46:30 +0000</pubDate><author>gywndi@gmail.com (gywndi)</author>
      <guid>//localhost:1313/2012/03/new-tweet-store/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;트위터는 하루 평균 2.5억 건의 트윗을 저장한다고 합니다. 과거 트위터는 날짜 기준으로 데이터를 분할 관리하여 저장을 하였고, 대략 3주에 한번씩 서버를 추가하여 Scale-out 하였습니다.&lt;/p&gt;&#xA;&lt;p&gt;하지만 이 방식에는 다음과 같은 문제가 있었습니다.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;부하 분산&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;고비용&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;복잡한 프로세스&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;문제를 해결하기 위해서 트위터에서 New Tweet Store를 고안했다고 합니다.&lt;/p&gt;&#xA;&lt;p&gt;자, 그럼 기존 문제점부터 차근차근 알아보도록 합시다^^;&lt;/p&gt;&#xA;&lt;h1 id=&#34;problems&#34;&gt;Problems&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;부하 분산(Load Balancing)&lt;/strong&gt;&lt;br&gt;&#xA;날짜 기준으로 데이터를 나눠서 분산 저장 및 관리하기 때문에, 시간이 지날수록 과거 데이터 조회 건수는 비약적으로 낮아집니다. 특히 대부분의 데이터 조회 요청은 현재 시각 기준으로 들어오기 때문에, 데이터 읽기 HOTSPOT이 발생할 수 밖에 없습니다.&#xA;&lt;img src=&#34;//localhost:1313/img/2012/03/old_load_balancing.png&#34; alt=&#34;Load Balancing Problem&#34;&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
